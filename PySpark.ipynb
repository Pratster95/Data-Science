{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import math\n",
    "import shutil\n",
    "from pyspark import SparkContext\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write one python function per item in the list below that uses Spark to compute the desired information. Each function should accept two arguments: a path to the graph.tsv file and a path to an output directory. Use Spark's saveAsTextFile() to save the final RDD to the specified output directory. Note that, by default, if the target output directory already exists when you attempt to save to it, you'll get an error. One solution is to remove the target directory between runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each node, compute the outdegree (number of outgoing edges) and output the (node, count) pairs in sorted order by node. The code should be in a single function named outdegree()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file_path = 'graph.tsv'\n",
    "output_path = 'output_graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdegree(graph_file_path, output_path):\n",
    "     \n",
    "    try:\n",
    "        shutil.rmtree(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    graph_data = sc.textFile(graph_file_path)\n",
    "    rdd = graph_data.map(lambda y: y.split('\\t')).map(lambda x: [int(val) for val in x])\n",
    "    print(\"Saving In Process\")\n",
    "    rdd.map(lambda y: (y[0], 1)).reduceByKey(add).sortByKey(lambda x: x[0]).saveAsTextFile(output_path)\n",
    "    print(\"Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving In Process\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "outdegree(graph_file_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each node, compute the sum of weights of incoming edges and output the (node, weight_sum) pairs in order sorted by node. The code should be in a single function named weight()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(graph_file_path, output_path):\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    data = sc.textFile(graph_file_path)\n",
    "    rdd = data.map(lambda l: l.split('\\t')).map(lambda x: [int(val) for val in x])\n",
    "    print(\"Saving In Process\")\n",
    "    rdd.map(lambda l: (l[1], l[2])).reduceByKey(lambda x, y: x+y).sortByKey(lambda x: x[0]).saveAsTextFile(output_path)\n",
    "    print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving In Process\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "weight(graph_file_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each node X, find a list of all other nodes Y such that there is an (X, Y) edge in the graph and a (Y, X) edge in the graph, and output the (X, [Y1, Y2, ..., Yn]) pairs in order sorted by X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs(graph_file_path, output_path):    \n",
    "    try:\n",
    "        shutil.rmtree(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    graph_data = sc.textFile(graph_file_path)\n",
    "    rdd = graph_data.map(lambda l: l.split('\\t')).map(lambda x: [int(val) for val in x])\n",
    "    print(\"Saving In Process\")\n",
    "    graph_data1 = rdd.map(lambda l: ((l[0], l[1]), 1)).sortByKey(lambda x:x[0])\n",
    "    graph_data2 = rdd.map(lambda l: ((l[1], l[0]), 1)).sortByKey(lambda x:x[1])\n",
    "    p = graph_data1.subtractByKey(graph_data2)\n",
    "    graph_data1.subtractByKey(p).sortByKey(lambda x: x[1]).saveAsTextFile(output_path)\n",
    "    print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving In Process\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "pairs(graph_file_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
